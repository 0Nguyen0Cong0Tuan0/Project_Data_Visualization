{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install countryinfo geopy pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from countryinfo import CountryInfo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from tqdm import tqdm \n",
    "\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geolocator = Nominatim(user_agent=\"vietnam_locations_app\")\n",
    "\n",
    "# def get_lat_lon(place):\n",
    "#     \"\"\"Fetch latitude and longitude for a given place.\"\"\"\n",
    "#     try:\n",
    "#         location = geolocator.geocode(place, timeout=10)\n",
    "#         if location:\n",
    "#             return location.latitude, location.longitude\n",
    "#         else:\n",
    "#             return None, None\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error geocoding {place}: {e}\")\n",
    "#         return None, None\n",
    "\n",
    "# def gather_vietnam_data():\n",
    "#     \"\"\"Collect latitude and longitude for all provinces in Vietnam.\"\"\"\n",
    "#     data = []\n",
    "    \n",
    "#     try:\n",
    "#         vietnam = CountryInfo(\"Vietnam\")\n",
    "#         provinces = vietnam.provinces() if hasattr(vietnam, \"provinces\") else [\"Vietnam\"]\n",
    "\n",
    "#         for province in tqdm(provinces, desc=\"Processing provinces\"):\n",
    "#             province_query = f\"{province}, Vietnam\"\n",
    "#             prov_lat, prov_lon = get_lat_lon(province_query)\n",
    "\n",
    "#             data.append({\n",
    "#                 \"Country\": \"Vietnam\",\n",
    "#                 \"State/Province\": province,\n",
    "#                 \"Latitude\": prov_lat,\n",
    "#                 \"Longitude\": prov_lon\n",
    "#             })\n",
    "\n",
    "#             time.sleep(1)  # Prevents rate limiting\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing Vietnam: {e}\")\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# print(\"Gathering Vietnam location data...\")\n",
    "# vietnam_data = gather_vietnam_data()\n",
    "\n",
    "# df = pd.DataFrame(vietnam_data)\n",
    "\n",
    "# df = df.dropna(subset=['Latitude', 'Longitude'], how='all')\n",
    "\n",
    "# num_parts = 5\n",
    "# split_dfs = np.array_split(df, num_parts)\n",
    "\n",
    "# for i, part_df in enumerate(split_dfs, start=1):\n",
    "#     output_file = f\"vietnam_locations_part_{i}.csv\"\n",
    "#     part_df.to_csv(output_file, index=False)\n",
    "#     print(f\"Saved {len(part_df)} entries to {output_file}\")\n",
    "\n",
    "# print(f\"Total entries: {len(df)} (split into {num_parts} parts)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: vietnam_locations_part_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Weather Data (Part 1):   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for Hai Phong...\n",
      "Rate limit reached for Hai Phong. Retrying in 10 seconds...\n",
      "Rate limit reached for Hai Phong. Retrying in 20 seconds...\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "start_year = 2020\n",
    "end_year = 2020\n",
    "\n",
    "location_files = [\n",
    "    # \"vietnam_locations_part_1.csv\",\n",
    "    # \"vietnam_locations_part_2.csv\",\n",
    "    \"vietnam_locations_part_3.csv\",\n",
    "    \"vietnam_locations_part_4.csv\",\n",
    "    \"vietnam_locations_part_5.csv\"\n",
    "]\n",
    "\n",
    "def get_historical_weather(province, lat, lon):\n",
    "    \"\"\"Fetch historical weather data for a given province with retry mechanism.\"\"\"\n",
    "    start_date = f\"{start_year}-01-01\"\n",
    "    end_date = f\"{end_year}-12-31\"\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": [\n",
    "            \"weathercode\", \"temperature_2m_max\", \"temperature_2m_min\",\n",
    "            \"apparent_temperature_max\", \"apparent_temperature_min\",\n",
    "            \"sunrise\", \"sunset\", \"daylight_duration\", \"sunshine_duration\",\n",
    "            \"uv_index_max\", \"uv_index_clear_sky_max\", \"precipitation_sum\",\n",
    "            \"rain_sum\", \"showers_sum\", \"snowfall_sum\", \"precipitation_hours\",\n",
    "            \"precipitation_probability_max\", \"windspeed_10m_max\",\n",
    "            \"windgusts_10m_max\", \"winddirection_10m_dominant\",\n",
    "            \"shortwave_radiation_sum\", \"et0_fao_evapotranspiration\"\n",
    "        ],\n",
    "        \"timezone\": \"auto\"\n",
    "    }\n",
    "\n",
    "    retries = 5 \n",
    "    wait_time = 10  \n",
    "\n",
    "    for _ in range(retries):\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        elif response.status_code == 429:\n",
    "            print(f\"Rate limit reached for {province}. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "            wait_time *= 2  \n",
    "        else:\n",
    "            print(f\"Error fetching data for {province}: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "    print(f\"Skipping {province} after {retries} failed attempts.\")\n",
    "    return None\n",
    "\n",
    "for file_num, location_file in enumerate(location_files, start=1):\n",
    "    print(f\"\\nProcessing file: {location_file}\")\n",
    "    province_data = pd.read_csv(location_file)\n",
    "    \n",
    "    weather_history = []\n",
    "    \n",
    "    for _, row in tqdm(province_data.iterrows(), total=len(province_data), desc=f\"Fetching Weather Data (Part {file_num})\"):\n",
    "        province = row[\"State/Province\"]\n",
    "        lat, lon = row[\"Latitude\"], row[\"Longitude\"]\n",
    "\n",
    "        print(f\"Fetching data for {province}...\")\n",
    "        data = get_historical_weather(province, lat, lon)\n",
    "\n",
    "        if data and \"daily\" in data:\n",
    "            daily_data = data[\"daily\"]\n",
    "            dates = daily_data[\"time\"]\n",
    "\n",
    "            for i in range(len(dates)): \n",
    "                weather_history.append([\n",
    "                    province,\n",
    "                    dates[i],\n",
    "                    daily_data[\"weathercode\"][i],\n",
    "                    daily_data[\"temperature_2m_max\"][i],\n",
    "                    daily_data[\"temperature_2m_min\"][i],\n",
    "                    daily_data[\"apparent_temperature_max\"][i],\n",
    "                    daily_data[\"apparent_temperature_min\"][i],\n",
    "                    daily_data[\"sunrise\"][i],\n",
    "                    daily_data[\"sunset\"][i],\n",
    "                    daily_data[\"daylight_duration\"][i],\n",
    "                    daily_data[\"sunshine_duration\"][i],\n",
    "                    daily_data[\"uv_index_max\"][i],\n",
    "                    daily_data[\"uv_index_clear_sky_max\"][i],\n",
    "                    daily_data[\"precipitation_sum\"][i],\n",
    "                    daily_data[\"rain_sum\"][i],\n",
    "                    daily_data[\"showers_sum\"][i],\n",
    "                    daily_data[\"snowfall_sum\"][i],\n",
    "                    daily_data[\"precipitation_hours\"][i],\n",
    "                    daily_data[\"precipitation_probability_max\"][i],\n",
    "                    daily_data[\"windspeed_10m_max\"][i],\n",
    "                    daily_data[\"windgusts_10m_max\"][i],\n",
    "                    daily_data[\"winddirection_10m_dominant\"][i],\n",
    "                    daily_data[\"shortwave_radiation_sum\"][i],\n",
    "                    daily_data[\"et0_fao_evapotranspiration\"][i]\n",
    "                ])\n",
    "\n",
    "        time.sleep(1) \n",
    "\n",
    "    csv_filename = f\"vietnam_historical_weather_part_{file_num}.csv\"\n",
    "    with open(csv_filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\n",
    "            \"Province\", \"Date\", \"Weather Code\", \"Max Temp (°C)\", \"Min Temp (°C)\", \n",
    "            \"Max Apparent Temp (°C)\", \"Min Apparent Temp (°C)\", \"Sunrise\", \"Sunset\",\n",
    "            \"Daylight Duration (s)\", \"Sunshine Duration (s)\", \"UV Index Max\", \n",
    "            \"UV Index Clear Sky Max\", \"Precipitation (mm)\", \"Rain (mm)\", \n",
    "            \"Showers (mm)\", \"Snowfall (mm)\", \"Precipitation Hours\", \n",
    "            \"Precipitation Probability Max (%)\", \"Max Wind Speed (m/s)\", \n",
    "            \"Max Wind Gusts (m/s)\", \"Dominant Wind Direction (°)\", \n",
    "            \"Shortwave Radiation Sum (MJ/m²)\", \"Reference Evapotranspiration (mm)\"\n",
    "        ])\n",
    "        writer.writerows(weather_history)\n",
    "\n",
    "    print(f\"Historical weather data saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb0 in position 37: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m csv_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvietnam_historical_weather_part_*.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m csv_files], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m merged_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvn_weather_2020.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mto_csv(merged_filename, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb0 in position 37: invalid start byte"
     ]
    }
   ],
   "source": [
    "csv_files = glob.glob(\"vietnam_historical_weather_part_*.csv\")\n",
    "\n",
    "merged_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "\n",
    "merged_filename = \"vn_weather_2020.csv\"\n",
    "merged_df.to_csv(merged_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
